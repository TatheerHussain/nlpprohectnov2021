# Hate-Speech Detection using Roman-Urdu
> The idea is to create a new hate speech detection in roman URDU language, that could out perform current systems out there.

### Technologies to be used

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![SciPy](https://img.shields.io/badge/SciPy-%230C55A5.svg?style=for-the-badge&logo=scipy&logoColor=%white)
![Web Scrapper](https://img.shields.io/badge/web%20Scrapper-scrapping-blue)
![NLTK](https://img.shields.io/badge/NLTK-toolkit-lightgrey)


# Steps to Follow 
1. Corpus Building 
    - There are presently no corpuses that could meet this studies requirements, thatâ€™s why starting from the begining could be a hectic job but for learing purpose this way is a plus point
2. Target Selection 
    - There is need to find the target of our corpus data, like ethnicity, religious, racism, nationality, casteism,  national Security. Although there are many such categories that can be selected as a domain like previous studies have done but I will choose few of them. 

    - The idea is to identify the hate/offensive speech in Roman Urdu social media posts against ethnicity, racism, religion, ethnic groups etc.
3. Labelling
    - Labelling the data based on offensive, hate, racism or not.
4. Data collection
    - Selected Keywords from Twitter and Facebook
        - Relevent Tweets/posts 
        - removing unnecessary data like urls,hashtags etc
        - Refining the data

### Proposed Methodology 

1. Training the Data
2. Preprocessing
3. Tf-Idf
    - Algorithms (yet to decide)
        - Traning Labels 
        - Baseline model
            - Test data 
            - Label Predictions 
                - Result validations 
                    - Test lables 
                    - Final results

## Usefull reporositories that are important to understand for this projects 

1. [Urdu Corpus Summary](https://github.com/humsha/USCorpus/tree/master/UrduSummaryCorpus)
2. [Urdu characters](https://github.com/urduhack/urdu-characters)
3. [Urdu-Word-Segmentation, Python](https://github.com/harisbinzia/Urdu-Word-Segmentation)
4. [Urdu Chatbot Jupiter Notebook](https://github.com/sirmadhashmi/ChatBot-Urdu-Example/blob/master/ChatBotUrdu.ipynb)
5. [Collection of Urdu Datasets](https://github.com/mirfan899/Urdu)
6. [more details about urdu](https://r12a.github.io/scripts/arabic/urdu)


# Aim of this study


The focus of this study:
* Devlop a benchmark corpus that can be used for the identification of hateful content.
* There are no generic and standardized guidelines that can be used to detect hatespeech in urdu language.
* There is a dire absence of hatespeech dataset in Roman-Urdu dataset, there are few but they are either extracted from hindi datasets or the data is too low to be used to training purposes
